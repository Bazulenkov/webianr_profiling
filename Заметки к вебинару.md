## Разбираем на практике ручное профилирование и статические профайлеры

В качестве учебного проекта возьмем уже избитую в предыдщем спринте задачу:
слайд:
	Простые делители числа 13195 — это 5, 7, 13 и 29.  
	Какой самый большой делитель числа 600851475143, являющийся простым числом?

Простое решение "в лоб" (наивный алгоритм)
	Показываю код в pycharm native.py

на маленьком числе работает, на большом числе ядро 100%, программа не завершается...

### Метод пристального взгляда
pycharm native.py.py

Открываем код и внимательно на него смотрим. Понимаем (если повезёт, то понимаем быстро), что для поиска делителей числа **N** нам нет смысла перебирать числа из интервала **sqrt(N)+1…N-1**, т.к. все делители из этого диапазона мы уже нашли при переборе чисел из интервала **2…sqrt(N)**. Слегка модифицируем код

Хочу напомнить про тестирование через docstrings
```bash
python -m doctest -v <file>
```


```bash
python -m doctest -v optimized.py
```
Для проверки ещё раз запускаем программу с числом, делители которого нам известны.
Cубъективно программа отработала гораздо быстрее, значит снова запускаем её с интересующим нас числом 600851475143.

Задача решена, мы чувствуем моральное удовлетворение.

Программа выполнилась за приемлимое время (меньше минуты), ответ получен верный, смысла в дальнешей оптимизации в данном конкретном случае нет, т.к. поставленную задачу мы решили. Как мы помним, самое важное в оптимизации — уметь вовремя остановиться.

### Ручное профилирование

1) Вставляем 
```python
start = time.time()
<код>
duration = time.time() - start
print(f'{duration}')
```
2) Пишем простенький декоратор и вешаем его на функцию:
```python
def timer(func):
"""Decorator for measure time function."""

	def wrapper(*args, **kwargs):
		start = time.time()
		result = func(*args, **kwargs)
		duration = time.time() - start
		print(f"Time of {func.__name__}: {duration:.05f}")
		return result

	return wrapper
```
3) Один из самых распространённых способов быстро прикинуть «что к чему». В самом элементарном случае, если мы используем unix-утилиту «time» это выглядит так (до оптимизации):
```bash
time python native.py 13195
Answer: 29

real    0m0.405s
user    0m0.405s
sys     0m0.000s
```
После оптимизации:
```bash
time python optimized.py 13195
Answer: 29

real    0m0.012s
user    0m0.008s
sys     0m0.004s
```
Ускорение в 405 /12 = 33 раза


4) Либо с использованием специального модуля «[timeit](https://docs.python.org/3.11/library/timeit.html)», который предназначен для измерения быстродействия небольших программ. Пример применения:
```bash
python -m timeit -n 10 -s 'from optimized import find_prime_factors' 'find_prime_factors(13195)'

10 loops, best of 5: 18.8 usec per loop

```



### Детерминированное профилирование

#### cProfile

```python
import cProfile
import ptest

cProfile.run('ptest.main()')
```
На этот раз мы видим, что у программы ушло **3.5 секунды** на запуск. **cProfile** выявил медленную функцию, которая **тратит 3 секунды** на запуск. Это и есть самая «**слабая**» часть основной функции. Обычно, когда вы обнаруживаете такие места, вы можете попытаться найти самый быстрый способ выполнения вашего кода, или прийти к выводу, что такая задержка приемлема. В этом примере, мы знаем, что лучший способ ускорить функцию, то убрать вызов [time.sleep](https://python-scripts.com/datetime-time-python), или, по крайней мере, снизить продолжительность сна. Вы можете также вызвать **cProfile** в командной строке, вместо применения в интерпретаторе. Как это сделать:
```bash
python -m cProfile ptest.py
```
Запишем вывод в файл:
```bash
python -m cProfile -o output.txt ptest.py
```

#### pstats (Анализ результатов профилирования)
```python
import pstats
p = pstats.Stats("output.txt")

p.strip_dirs().sort_stats(-1).print_stats()
```
Вызов **strip_dirs** вырезает все пути к модулям из вывода, пока вызов **sort_stats** делает сортировку, которая нужна нам для виденья картины.
Документация [cProfile](https://docs.python.org/3.11/library/profile.html?highlight=cprofile).

#### line_profiler
```bash
pip install line_profiler

kernprof -vl optimized.py 13195
```

Сразу замечаем огромный оверхед: программа выполнялась больше 30 секунд, при том, что без профайлера она отрабатывает быстрее, чем за секунду._  


#### memory_profiler
```
pip install psutil memory_profiler

python -m memory_profiler optimized.py 13159
```


Sentry - у них сейчас появился раздел Profiling (пока beta)
https://docs.sentry.io/product/profiling/


У метода есть и недостатки, и самый главный из них заключается в отсутствии зависимости от входных данных. Так, для функции определения простого числа «is_prime» время выполнения будет сильно зависеть от величины этого числа, и если эта функция в проекте вызывается очень часто график окажется совершенно бессмысленным. Важно чётко понимать где какой подход можно использовать и что мы имеем на выходе.

Потом показал профилирование в PyCharm


